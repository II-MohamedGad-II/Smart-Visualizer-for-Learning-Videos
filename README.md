# ğŸ¬ Educational Video Visualizer â€“ Transcript-to-Image Overlay Pipeline

This notebook takes an educational video and automatically enhances it by:

1. **Transcribing the speech** using OpenAIâ€™s Whisper model.
2. **Identifying the most visually descriptive or conceptually rich moments** in the video using a large language model (LLM) like DeepSeek or Mistral.
3. **Generating images** from those moments using Stable Diffusion.
4. **Overlaying the generated images** at the right timestamps in the video to improve engagement and understanding.

---

## ğŸ“¦ Features

- âœ… Converts video to audio in-memory using `ffmpeg`
- âœ… Transcribes using Whisper (`base` model)
- âœ… Extracts most visualizable ideas via a prompt to an LLM
- âœ… Parses the LLM response into structured segments
- âœ… Uses Stable Diffusion (`CompVis/stable-diffusion-v1-4`) to generate matching images
- âœ… Overlays generated images on video using MoviePy

---

## ğŸ“ Files

- `Notebook.ipynb` â€“ Main notebook containing all logic
- `E:/course.mp4` â€“ Sample input video (you should replace with your own)

---

## ğŸš€ How to Run

### 1. ğŸ”§ Install Requirements

Make sure you are using a Python environment with GPU access.

```bash
pip install -r requirements.txt
